{
  "hash": "85c690871bd4511a0fe8eb9cc4003de4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ncategories: \"Lab 3\"\nexecute:\n  eval: true\nformat:\n  html:\n    code-link: true #Supposed to create a link to documentation but its not, for some reason.\n   # code-block-bg: true # \"lightblue\" Does not work well with dark mode.\n    code-block-border-left: \"#31BAE9\"\n    code-fold: show #also try true OR false and decide if you like it.\n    code-tools: false\n    code-copy: true\ntitle: Importing Data into R\n---\n\n\n\n\n\n# Introduction {.unnumbered}\n\nThe goal of this lab is to introduce you to the concept of importing data into R. In the previous labs, we have been using data that is already available in R or in R packages. However, in real life, you will often need to import data from external sources such as Excel, CSV, or text files. In this lab, we will learn how to \"import\" data into R from various sources including:\n\n-   Spreadsheets:\n    - Excel files\n    - Google Sheets\n-   CSV files\n-   Text files\n-   Databases\n\n# Packages\n\nIn this lab, you will need the following packages.\n\n-   `readxl` for reading excel files\n-   `googlesheets4` for reading data from Google Sheets\n-   `RSQLite` for connecting to databases\n-   `Tidyverse` packages:\n    -   `readr` for reading CSV and TSV files. Part of Tidyverse.\n    -   `dbplyr` for working with relational data. Part of Tidyverse.\n    -   `dplyr` for data manipulation. Part of Tidyverse.\n\nStart by installing any packages that you don't already have (likely the first three) then create a code chunk for loading the packages. Note that package installation is to be done in the console using the `install.packages(\"package name\")` command.\n\nLoad packages in the packages code chunk as shown below:\n\n``` toml\nlibrary(readxl)\nlibrary(googlesheets4)\nlibrary(RSQLite)\nlibrary(tidyverse)\n```\n\n# Importing from Spreadsheets\n\n## Excel Files\n\nReading excel files into R is made possible by the `readxl` package (installed above).\n\nTo read an excel file into R, we use the `read_excel()` function from the `readxl` package. Follow these steps:\n\na.  Obtain your excel data (.xslx) data set and upload it into your project (files section) using the upload option.\n\nb.  Click on the file then choose the **import dataset** option (see figure below). This will open a pop-up window that shows a preview of the data set and the file path. Click on import.\n\n    ![Importing an Excel Spreadsheet](/img/%20d.png){fig-align=\"center\" width=\"100%\"}\n\nc.  Finally, open a code chunk for your data and use the `read_excel()` function to read the file into R as shown below. If the file is in a folder, make sure to set the correct path.\n\n``` toml\nread_excel(\"filename.xlsx\")\n```\n\n***Practice:*** You received an email with an attachment of an excel data set named absenteeism. Read file into your R.\n\n## Google Sheets\n\nGoogle is a popular cloud-based platform for storing and sharing data. To read data stored in Google sheets, we the package `googlesheets4`.\n\nThe fact that Google documents live in the cloud makes sharing and updating data easy especially if there are multiple people collaborating on the same project. Since `googlesheets4` allows R to read the data from Google directly, you do not have to download the data. If you share a link with edit privileges, people can enter the data directly and you can analyze it in real-time.\n\n### *Google Sheets API*\n\nSince R and Google Sheets are different products, the two have to communicate in some way. This happens through what is known as ***Application Programming Interface (API)***. APIs are means through which different applications are able to communicate with one another. Google has an API that allows R to communicate with Google Sheets. To use this API, you will need to authenticate your R session with Google every time.\n\n### *Authenticating API with Google*\n\nTo set up the connection between Google Sheets and R, start by running the command `gs4_auth()` in the console. This will open a new page in your browser that asks you which Google account you’d like to have access to. Click on the appropriate Google user to provide `googlesheets4` access to the Google Sheets API. After this, you will be given a code that you will need to copy and paste into your R console. This will authenticate your R session with Google Sheets.\n\n### *Reading Data from Google Sheets*\n\nThe last step is to read the data into R. We use the function `read_sheet()` for this. The function takes the URL of the Google Sheet as an argument. The URL can be obtained by clicking on the share button on the Google Sheet and copying the link. Make sure you have the correct permissions to access the data.\n\nAs an example, we will read in a data set available on the link <https://docs.google.com/spreadsheets/d/1pEJ6vuGmyWrNPjHSorvIANAAvGBctRgpp1_mEBZkN-Q/edit?usp=sharing> \nThis is the same absenteeism data set that we read from an excel file earlier. Use the code below (notice that we are saving the data as g_sheet):\n\n``` toml\ng_sheet <-read_sheet(\"https://docs.google.com/spreadsheets/d/1Q\n```\n\n# CSV Files\n\nCSV stands for Comma Separated Values. It is a simple file format used to store tabular data, such as a spreadsheet or database. CSV files are plain text files that contain data separated by commas and are preferred by many data scientists because of their simplicity. To read a CSV file into R, you can use the `read_csv()` function from the `readr` package. The `readr` package is part of the `tidyverse` package, so you do not need to install it separately if you have `tidyverse` already. The process for reading in csv files is very similar to that of excel file.\n\nHere are the steps:\n\na.  Obtain your CSV data set and upload it into your Project (files section) using the upload option.\n\nb.  Click on the file then choose the **import dataset** option. This will open a pop-up window that shows a preview of the data set and the file path. Click on import.\n\nc.  Finally, open a code chunk for your data and use the `read_csv(\"filename\")` function to read the file into R as shown below. If the file is in a folder, make sure to get the correct path.\n\n***Practice:*** Download the csv file named baby_names from the the sits <https://www.openintro.org/data/index.php?data=baby_names> and read it in your R project.\n\n# Text Files (TSVs)\n\nAnother common form of data is text files that usually come in the form of TXT or TSV file formats. Like CSVs, text files are simple, plain-text files; however, rather than columns being separated by commas, they are separated by tabs (represented by \" in plain-text). Like CSVs, they don’t allow text formatting (i.e. text colors in cells) and are able to be opened on many different software platforms. This makes them good candidates for storing data.\n\nTo read a TSV file into R, you can use the `read_tsv()` function from the `readr` package. The process for reading in TSV files is very similar to that of CSV files.\n\n\n# Databases\n\nUp to this point, we have considered data stored as a single file in various formats. However, in many real life scenarios, data are often stored in databases. A database is a collection of data that are organized so that they can be easily accessed, managed, and updated. A key point to note about databases is that they are designed to store large amounts of data. There are many types of databases, but the most common ones are ***relational databases***.\n\n## **Relational Databases**\n\nIn a relational database, data is stored in tables, and the tables are related to each other. As an example, consider a college database that has several tables about their students including\n\n-   ***Demographics:*** ID, name, email, year of study, etc.\n-   ***Courses:*** ID, course name, credits, grade, department, etc.\n-   ***Instructors:*** ID, name, email, rank, etc.\n\nAlthough each table contains different information, there is a common column in each of the tables that allows information to be linked (in this **ID**). The **ID** values are referred to as ***unique identifiers*** because they uniquely identify each student. No two students will have the same **ID**.\n\n## **Advantages**\n\nStoring data in databases is considered *secure*, *efficient*, and *reduces ambiguity*.\n\n-   The *efficiency* comes from the fact that databases are optimized for reading and writing data. Storing data in separate tables also limits the need to repeat information.\n\n-   The *security* comes from the fact that databases can be set up to allow only authorized users to access certain data. If the data were all stored in one table, you lose this advantage.\n\n-   *Ambiguity* is reduced by, among other things, the fact that databases are better at handling multiple cases with same name but different characteristics.\n\n## **Database Storage**\n\nDatabases are stored in a database management system (DBMS). A DBMS is a software that allows you to interact with the database. The most common DBMS are MySQL and SQLite. In order to use data stored in a data base, there has to be a way to pull information from the database. Doing this is called ***querying the database***. For example, one may want to know all female students who took MATH 240 at IC in the last 5 years. To do this, one would have to use SQL query commands. Using SQL commands is beyond the scope of this course, but you will learn how to use an R package known as `RSQLite` for establishing a connection to a database and using `dbplr` and `dbplyr` to work with relational data.\n\n## **Connecting to a Database**\n\nWe are going to use a database called `comany.db` containing several tables with information about digital media (artistes, customers, artiste's work, etc). We are going to focus only on `artists` and the `albums` tables. The unique identifier here will be `artistId`.\n\n![Image credit: Carrie Wright, et al.](/img/e.png){fig-align=\"center\"}\n\nFollow the following steps to connect to the database:\n\n1.  Download the database from [this link](https://drive.google.com/file/d/19u68_tknOIM_IPBQlvA7kTl2aTxbLH-v/view?usp=sharing) and unzip it. Upload it to your project.\n\n2.  Install and load the `RSQLite` package.\n\n    ``` toml\n    install.packages(\"RSQLite\")\n    # Do this in the console\n    ```\n\n    ``` toml\n    library(RSQLite)\n    # Do this in the packages code chunk\n    ```\n\n3.  Specify driver and create a connection to the database.\n\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    sqlite <- dbDriver(\"SQLite\")\n    ```\n    :::\n\n\n\n4.  Create a connection to the database using the command below. Notice that the connection is saved as an object named `con`.\n\n    ``` toml\n    con <- dbConnect(sqlite, \"company.db\")\n    ```\n\n\n\n    \n\n\n\n***Note:*** that if you are using desktop version of R, you will need to specify a path to the database file.\n\n## **Viewing Table List**\nFirst, we want to know the tables contained in this database. To do this, use the function `dbListTables()` as shown below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbListTables(con)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"albums\"          \"artists\"         \"customers\"       \"employees\"      \n [5] \"genres\"          \"invoice_items\"   \"invoices\"        \"media_types\"    \n [9] \"playlist_track\"  \"playlists\"       \"sqlite_sequence\" \"sqlite_stat1\"   \n[13] \"tracks\"         \n```\n\n\n:::\n:::\n\n\n\nNotice that there are 13 tables, but we are only interested in the `artists` and `albums` tables.\n\nAlthough here we are using a downloaded database, the common practice is to connect to databases remotely especially if they are huge in size.\n\n## **Extracting Data**\n\nWe will use the `dbplyr` package to access the tables we are interested in. Start by loading the package in the packages chunk. The package works under the hood with `dplyr` to allow you to work with databases as if they were data frames. You will not notice that you are using the `dbplyr`.\n\nTo extract the `artists` table, use the command below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nartists <- tbl(con, \"artists\")\n```\n:::\n\n\n\nTo extract the `albums` table, use the command below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalbums <- tbl(con, \"albums\")\n```\n:::\n\n\n\nYou want to view the tables as `tibbles` (nice format that works well with tidyverse). To do this, use the `as_tibble()` function as shown below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nartists_tibble <- as_tibble(artists)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nalbums_tibble <- as_tibble(albums)\n```\n:::\n\n\n\n\n## **Joining Tables: Mutating Joins**\n\nBefore you do your analyses, you may want to merge the tables. This is done using joins. There are several types of joins, but the most common ones are:\n\n-   ***Inner join:*** This only keeps observations found in both left(`x`) and right (`y`) tables.\n-   ***Left join:*** This keeps all observations in the left table (artists) and only those in the right table (albums) that match.\n-   ***Right join:*** This keeps all observations in the right table and only those in the left table that match.\n-   ***Full join:*** This keeps any observations in `x` or `y`.\n\n### **Inner Joins**\n\nBelow is a diagrammatic illustration of an inner join:\n\n![Image credit: Carrie Wright, et al.](/img/inner.png){fig-align=\"center\" width=\"80%\"}\n\nTo join the `artists` and `albums` tables using an inner join, we use the function `inner_join()` as shown below. Notice that we are using tibble format for both albums and artists because tidyverse works best in this format.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninner_data <- inner_join(artists_tibble, albums_tibble, by = \"ArtistId\")\n```\n:::\n\n\n\n### **Left Joins**\n\nBelow is a diagrammatic illustration of a left join:\n\n![Image credit: Carrie Wright, et al.](/img/left.png){fig-align=\"center\" width=\"80%\"}\n\nTo join the `artists` and `albums` tables using a left join, we use the function `left_join()` as shown below:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_data <- left_join(artists_tibble, albums_tibble, by = \"ArtistId\")\n```\n:::\n\n\n\n\n### **Right Joins**\n\nA right join is similar to a left join, but it keeps all observations in the right table and only those in the left table that match. Right joins return rows with NA values in the left table where there is no match. To join the `artists` and `albums` tables using a right join, we use the function `right_join()` as shown below.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nright_data <- right_join(artists_tibble, albums_tibble, by = \"ArtistId\")\n```\n:::\n\n\n\n\n***Note:*** The fact that 347 rows are present with the right join and 418 were present after the left join suggests that there are artists in the artists table without albums in the albums table.\n\n\n### **Full Joins**\n\nLastly, a full join keeps any observations in `x` or `y`. NAs are used when data are missing for an observation(s). To join the `artists` and `albums` tables using a full join, we use the function `full_join()` as shown below.\n \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_data <- full_join(artists_tibble, albums_tibble, by = \"ArtistId\")\n```\n:::\n\n\n\n***Note:*** \n\n- To learn more about joins, Garrick Aden-Buie has a great resource on GitHub. Check it out: [here](https://github.com/gadenbuie/tidyexplain).\n- Our focus was on mutating joins. There are also the aspect of filtering joins that focuses on observations (rows). \n\n\n# Exporting Data from R\n\nAfter you have analyzed your data in R, you may want to export the results back to a file. It is also possible that you have performed some data wrangling and you want to share the file with someone else. To do this, you need to learn how to export a dataset from R. The most common formats for exporting data are: csv, excel, and text files. Here is how to go about it:\n\nAssuming your data frame is called `my_data`, and you want to export under the name `my_new_data`, you can use the following commands:\n\n***To exports to CSV, use:***\n\n``` toml\nwrite_csv(my_data, path = \"my_new_data.csv\")\n```\n\n***To export to Excel, use:***\n\n``` toml\nwrite_excel_csv(my_data, path = \"my_new_data.xlsx\")\n```\n\n***To export to a text file, use:***\n\n``` toml\nwrite_tsv(my_data, path = \"my_new_data.txt\")\n```\n\nRunning the above commands will create a new file in your project folder with the name `my_new_data` and the appropriate file extension. You can then download the file and share it with others.\n\n\n\n\n# Exercises\n\n\n \n \n \n \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}